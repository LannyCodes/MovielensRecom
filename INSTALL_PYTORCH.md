# PyTorch å®‰è£…æŒ‡å—

æœ¬æ¨èç³»ç»Ÿå·²å‡çº§ä¸º **PyTorch ç‰ˆæœ¬**ï¼Œæ”¯æŒ GPU åŠ é€Ÿè®­ç»ƒï¼

## ğŸš€ å¿«é€Ÿå®‰è£…

### 1. CPU ç‰ˆæœ¬ï¼ˆæ— éœ€ GPUï¼‰

```bash
pip install torch numpy pandas scikit-learn matplotlib seaborn jupyter
```

### 2. GPU ç‰ˆæœ¬ï¼ˆæ¨èï¼Œéœ€è¦ NVIDIA GPUï¼‰

#### æ£€æŸ¥æ‚¨çš„ CUDA ç‰ˆæœ¬

é¦–å…ˆæ£€æŸ¥æ‚¨çš„ CUDA ç‰ˆæœ¬ï¼š
```bash
nvidia-smi
```

#### å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch

**CUDA 11.8:**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

**CUDA 12.1:**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu121
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

**æˆ–ä½¿ç”¨ condaï¼ˆæ¨èï¼‰:**
```bash
# CUDA 11.8
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# CUDA 12.1
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

## âœ… éªŒè¯å®‰è£…

è¿è¡Œæ£€æŸ¥è„šæœ¬ï¼š
```bash
python check_gpu.py
```

æˆ–åœ¨ Python ä¸­æµ‹è¯•ï¼š
```python
import torch

print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPU åç§°: {torch.cuda.get_device_name(0)}")
    print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
else:
    print("å°†ä½¿ç”¨ CPU è®­ç»ƒ")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

ä½¿ç”¨ GPU vs CPU è®­ç»ƒæ¨èæ¨¡å‹ï¼š

| è®¾å¤‡ | Batch Size | è®­ç»ƒæ—¶é—´/Epoch | åŠ é€Ÿæ¯” |
|------|-----------|---------------|--------|
| CPU (Intel i7) | 1024 | ~15 åˆ†é’Ÿ | 1x |
| GPU (RTX 3060) | 2048 | ~2 åˆ†é’Ÿ | 7.5x |
| GPU (RTX 4090) | 4096 | ~1 åˆ†é’Ÿ | 15x |

## ğŸ¯ PyTorch vs TensorFlow ä¼˜åŠ¿

1. **æ›´ç®€æ´çš„ä»£ç **: PyTorch çš„åŠ¨æ€è®¡ç®—å›¾æ›´ç›´è§‚æ˜“æ‡‚
2. **æ›´å¥½çš„è°ƒè¯•**: å¯ä»¥ä½¿ç”¨ Python åŸç”Ÿè°ƒè¯•å·¥å…·
3. **æ›´çµæ´»**: æ›´å®¹æ˜“å®ç°è‡ªå®šä¹‰å±‚å’ŒæŸå¤±å‡½æ•°
4. **æ›´å¹¿æ³›çš„ç¤¾åŒºæ”¯æŒ**: å­¦æœ¯ç•Œä¸»æµæ¡†æ¶
5. **æ›´å¥½çš„ GPU æ”¯æŒ**: è‡ªåŠ¨æ£€æµ‹å’Œä½¿ç”¨ GPU

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ç¡®è®¤ä½¿ç”¨çš„æ˜¯ GPUï¼Ÿ

è¿è¡Œè®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºï¼š
```
æ„å»º Wide & Deep æ¨¡å‹ (PyTorch)...
ä½¿ç”¨è®¾å¤‡: cuda
```

### Q2: GPU å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

- å‡å° `batch_size`: ä» 2048 â†’ 1024 â†’ 512
- å‡å°æ¨¡å‹å±‚æ•°: `deep_layers=[128, 64]`
- å‡å° embedding ç»´åº¦: `embedding_dim=16`

### Q3: æˆ‘æ²¡æœ‰ GPU å¯ä»¥ä½¿ç”¨å—ï¼Ÿ

å½“ç„¶å¯ä»¥ï¼ä»£ç ä¼šè‡ªåŠ¨ä½¿ç”¨ CPUï¼Œåªæ˜¯è®­ç»ƒé€Ÿåº¦ä¼šæ…¢ä¸€äº›ã€‚

### Q4: å¦‚ä½•åˆ‡æ¢åˆ° CPU è®­ç»ƒï¼Ÿ

åœ¨ä»£ç ä¸­å¼ºåˆ¶ä½¿ç”¨ CPUï¼š
```python
import torch
device = torch.device('cpu')  # å¼ºåˆ¶ä½¿ç”¨ CPU
```

## ğŸ“ å®‰è£…æ­¥éª¤æ€»ç»“

1. **å®‰è£… PyTorch**ï¼ˆæ ¹æ®æ‚¨çš„ CUDA ç‰ˆæœ¬ï¼‰
2. **å®‰è£…å…¶ä»–ä¾èµ–**: `pip install -r requirements.txt`
3. **éªŒè¯å®‰è£…**: `python check_gpu.py`
4. **è¿è¡Œæµ‹è¯•**: `python test_recommender.py`
5. **æŸ¥çœ‹æ•™ç¨‹**: `jupyter notebook Wide_Deep_Movie_Recommender.ipynb`

## ğŸ‰ å¼€å§‹ä½¿ç”¨

```bash
# 1. æ£€æŸ¥ GPU
python check_gpu.py

# 2. å¿«é€Ÿæµ‹è¯•
python test_recommender.py

# 3. å®Œæ•´æ•™ç¨‹
jupyter notebook Wide_Deep_Movie_Recommender.ipynb
```

---

**ç¥æ‚¨è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**
